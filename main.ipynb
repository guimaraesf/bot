{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def set_logger(sc):\n",
    "    log4jLogger = sc._jvm.org.apache.log4j\n",
    "    logger = log4jLogger.LogManager.getLogger(__name__)\n",
    "    sc.setLogLevel('INFO')\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_sparksession(master, app_name):\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(app_name) \\\n",
    "        .master(master) \\\n",
    "        .config(\"spark.debug.maxToStringFields\", 100) \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    logger = set_logger(spark.sparkContext)\n",
    "\n",
    "    return spark, logger"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=beneficios-sociais, master=local[*]) created by getOrCreate at C:\\Users\\Fernando Guimarães\\AppData\\Local\\Temp\\ipykernel_19016\\3950296619.py:9 ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m master \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocal[*]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m app_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeneficios-sociais\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocal[*]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m spark \u001B[38;5;241m=\u001B[39m get_sparksession(master, app_name)\n",
      "File \u001B[1;32mC:\\Development\\repositorios\\bot\\.venv\\lib\\site-packages\\pyspark\\context.py:195\u001B[0m, in \u001B[0;36mSparkContext.__init__\u001B[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway\u001B[38;5;241m.\u001B[39mgateway_parameters\u001B[38;5;241m.\u001B[39mauth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    191\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    192\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not allowed as it is a security risk.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    193\u001B[0m     )\n\u001B[1;32m--> 195\u001B[0m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_init(\n\u001B[0;32m    198\u001B[0m         master,\n\u001B[0;32m    199\u001B[0m         appName,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    208\u001B[0m         udf_profiler_cls,\n\u001B[0;32m    209\u001B[0m     )\n",
      "File \u001B[1;32mC:\\Development\\repositorios\\bot\\.venv\\lib\\site-packages\\pyspark\\context.py:430\u001B[0m, in \u001B[0;36mSparkContext._ensure_initialized\u001B[1;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[0;32m    427\u001B[0m     callsite \u001B[38;5;241m=\u001B[39m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context\u001B[38;5;241m.\u001B[39m_callsite\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;66;03m# Raise error if there is already a running Spark context\u001B[39;00m\n\u001B[1;32m--> 430\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    431\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run multiple SparkContexts at once; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    432\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexisting SparkContext(app=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, master=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    433\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m created by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m at \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    434\u001B[0m         \u001B[38;5;241m%\u001B[39m (\n\u001B[0;32m    435\u001B[0m             currentAppName,\n\u001B[0;32m    436\u001B[0m             currentMaster,\n\u001B[0;32m    437\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mfunction,\n\u001B[0;32m    438\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mfile,\n\u001B[0;32m    439\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mlinenum,\n\u001B[0;32m    440\u001B[0m         )\n\u001B[0;32m    441\u001B[0m     )\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    443\u001B[0m     SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;241m=\u001B[39m instance\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=beneficios-sociais, master=local[*]) created by getOrCreate at C:\\Users\\Fernando Guimarães\\AppData\\Local\\Temp\\ipykernel_19016\\3950296619.py:9 "
     ]
    }
   ],
   "source": [
    "master = \"local[*]\"\n",
    "app_name = \"beneficios-sociais\"\n",
    "sc = SparkContext('local[*]')\n",
    "spark = get_sparksession(master, app_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'stop'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop\u001B[49m()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'stop'"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}